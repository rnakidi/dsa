𝟏. 𝐂𝐚𝐜𝐡𝐢𝐧𝐠
Temporarily storing frequently accessed data in memory to reduce access time.

How It Helps:
Data Retrieval: Fetching data from a cache (e.g., Redis, Memcached) is significantly faster than querying a database.
Content Delivery: Caching static assets (like images, CSS, JS) reduces the need to retrieve them from the origin server repeatedly.

𝟐. 𝐋𝐨𝐚𝐝 𝐁𝐚𝐥𝐚𝐧𝐜𝐢𝐧𝐠
Distributing incoming network traffic across multiple servers to ensure no single server becomes a bottleneck.

How It Helps:
Resource Utilization: Balances the load to prevent any single server from becoming overwhelmed, which can slow down response times.
Redundancy: Provides failover capabilities, ensuring requests are handled promptly even if some servers are down.

𝟑. 𝐀𝐬𝐲𝐧𝐜𝐡𝐫𝐨𝐧𝐨𝐮𝐬 𝐏𝐫𝐨𝐜𝐞𝐬𝐬𝐢𝐧𝐠
Handling tasks in the background without blocking the main execution thread, allowing the system to continue processing other requests.

How It Helps:
Non-blocking Operations: Users don't have to wait for long-running tasks (like sending emails or processing images) to complete.

𝟒. 𝐃𝐚𝐭𝐚 𝐏𝐚𝐫𝐭𝐢𝐭𝐢𝐨𝐧𝐢𝐧𝐠 (𝐒𝐡𝐚𝐫𝐝𝐢𝐧𝐠)
Dividing a database into smaller, more manageable pieces (shards) that can be distributed across multiple servers.

How It Helps:
Parallelism: Queries can be executed in parallel across shards, reducing the time to retrieve data.
Scalability: Distributes the load, preventing any single database instance from becoming a bottleneck.

𝟓. 𝐂𝐨𝐧𝐭𝐞𝐧𝐭 𝐃𝐞𝐥𝐢𝐯𝐞𝐫𝐲 𝐍𝐞𝐭𝐰𝐨𝐫𝐤𝐬 (𝐂𝐃𝐍𝐬)
Distributed networks of servers that deliver web content based on the geographic location of the user.

How It Helps:
Proximity: Serves content from servers closest to the user, reducing the physical distance data must travel.
Caching: Caches static and dynamic content to speed up delivery.

𝟔. 𝐃𝐚𝐭𝐚𝐛𝐚𝐬𝐞 𝐎𝐩𝐭𝐢𝐦𝐢𝐳𝐚𝐭𝐢𝐨𝐧
Tuning databases to perform queries more efficiently through indexing, query optimization, and proper schema design.

How It Helps:
Indexing: Speeds up data retrieval by allowing the database to find records without scanning entire tables.

𝟕. 𝐌𝐢𝐧𝐢𝐦𝐢𝐳𝐢𝐧𝐠 𝐍𝐞𝐭𝐰𝐨𝐫𝐤 𝐇𝐨𝐩𝐬
Reducing the number of intermediary steps data must pass through and choosing efficient communication protocols.

How It Helps:
Fewer Hops: Each network hop introduces additional latency; minimizing them speeds up data transmission.

𝟗. 𝐏𝐫𝐞𝐟𝐞𝐭𝐜𝐡𝐢𝐧𝐠 𝐚𝐧𝐝 𝐏𝐫𝐞𝐝𝐢𝐜𝐭𝐢𝐯𝐞 𝐋𝐨𝐚𝐝𝐢𝐧𝐠
Anticipating future data requests and loading them in advance.

How It Helps:
Reduced Wait Times: Data is already available when requested, eliminating retrieval delays.
Smoother User Experience: Especially effective in applications with predictable access patterns.
